v1
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/1.csv","timestamp":1620569818369,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/2.csv","timestamp":1620569819369,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/3.csv","timestamp":1620569820373,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/4.csv","timestamp":1620569821373,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/5.csv","timestamp":1620569822377,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/6.csv","timestamp":1620569823377,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/7.csv","timestamp":1620569824377,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/8.csv","timestamp":1620569825380,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/9.csv","timestamp":1620569826380,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/10.csv","timestamp":1620569827384,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/11.csv","timestamp":1620569828384,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/12.csv","timestamp":1620569829388,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/13.csv","timestamp":1620569830392,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/14.csv","timestamp":1620569831396,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/15.csv","timestamp":1620569832396,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/16.csv","timestamp":1620569833399,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/17.csv","timestamp":1620569834399,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/18.csv","timestamp":1620569835399,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/19.csv","timestamp":1620569836403,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/20.csv","timestamp":1620569837407,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/21.csv","timestamp":1620569838407,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/22.csv","timestamp":1620569839411,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/23.csv","timestamp":1620569840414,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/24.csv","timestamp":1620569841414,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/25.csv","timestamp":1620569842418,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/26.csv","timestamp":1620569843418,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/27.csv","timestamp":1620569844418,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/28.csv","timestamp":1620569845422,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/29.csv","timestamp":1620569846422,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/30.csv","timestamp":1620569847426,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/31.csv","timestamp":1620569848429,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/32.csv","timestamp":1620569849429,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/33.csv","timestamp":1620569850429,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/34.csv","timestamp":1620569851433,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/35.csv","timestamp":1620569852433,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/36.csv","timestamp":1620569853437,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/37.csv","timestamp":1620569854437,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/38.csv","timestamp":1620569855441,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/39.csv","timestamp":1620569856444,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/40.csv","timestamp":1620569857444,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/41.csv","timestamp":1620569858448,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/42.csv","timestamp":1620569859448,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/43.csv","timestamp":1620569860452,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/44.csv","timestamp":1620569861452,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/45.csv","timestamp":1620569862460,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/46.csv","timestamp":1620569863460,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/47.csv","timestamp":1620569864459,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/48.csv","timestamp":1620569865467,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/49.csv","timestamp":1620569866467,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/50.csv","timestamp":1620569867471,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/51.csv","timestamp":1620569868471,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/52.csv","timestamp":1620569869475,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/53.csv","timestamp":1620569870479,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/54.csv","timestamp":1620569871479,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/55.csv","timestamp":1620569872483,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/56.csv","timestamp":1620569873482,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/57.csv","timestamp":1620569874486,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/58.csv","timestamp":1620569875486,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/59.csv","timestamp":1620569876490,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/60.csv","timestamp":1620569877490,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/61.csv","timestamp":1620569878494,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/62.csv","timestamp":1620569879494,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/63.csv","timestamp":1620569880498,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/64.csv","timestamp":1620569881497,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/65.csv","timestamp":1620569882501,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/66.csv","timestamp":1620569883501,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/67.csv","timestamp":1620569884505,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/68.csv","timestamp":1620569885505,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/69.csv","timestamp":1620569886509,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/70.csv","timestamp":1620569887513,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/71.csv","timestamp":1620569888513,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/72.csv","timestamp":1620569889516,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/73.csv","timestamp":1620569890520,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/74.csv","timestamp":1620569891520,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/75.csv","timestamp":1620569892524,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/76.csv","timestamp":1620569893524,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/77.csv","timestamp":1620569894524,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/78.csv","timestamp":1620569895532,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/79.csv","timestamp":1620569896532,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/80.csv","timestamp":1620569897536,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/81.csv","timestamp":1620569898535,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/82.csv","timestamp":1620569899539,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/83.csv","timestamp":1620569900539,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/84.csv","timestamp":1620569901543,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/85.csv","timestamp":1620569902547,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/86.csv","timestamp":1620569903547,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/87.csv","timestamp":1620569904551,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/88.csv","timestamp":1620569905551,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/89.csv","timestamp":1620569906554,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/90.csv","timestamp":1620569907554,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/91.csv","timestamp":1620569908558,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/92.csv","timestamp":1620569909558,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/93.csv","timestamp":1620569910562,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/94.csv","timestamp":1620569911566,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/95.csv","timestamp":1620569912570,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/96.csv","timestamp":1620569913570,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/97.csv","timestamp":1620569914574,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/98.csv","timestamp":1620569915577,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/99.csv","timestamp":1620569916577,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/100.csv","timestamp":1620569917577,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/101.csv","timestamp":1620569918581,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/102.csv","timestamp":1620569919585,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/103.csv","timestamp":1620569920585,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/104.csv","timestamp":1620569921589,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/105.csv","timestamp":1620569922593,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/106.csv","timestamp":1620569923592,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/107.csv","timestamp":1620569924592,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/108.csv","timestamp":1620569925596,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/109.csv","timestamp":1620569926596,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/110.csv","timestamp":1620569927600,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/111.csv","timestamp":1620569928600,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/112.csv","timestamp":1620569929608,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/113.csv","timestamp":1620569930608,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/114.csv","timestamp":1620569931612,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/115.csv","timestamp":1620569932615,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/116.csv","timestamp":1620569933619,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/117.csv","timestamp":1620569934623,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/118.csv","timestamp":1620569935620,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/119.csv","timestamp":1620569936629,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/120.csv","timestamp":1620569937630,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/121.csv","timestamp":1620569938635,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/122.csv","timestamp":1620569939636,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/123.csv","timestamp":1620569940637,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/124.csv","timestamp":1620569941638,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/125.csv","timestamp":1620569942639,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/126.csv","timestamp":1620569943644,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/127.csv","timestamp":1620569944645,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/128.csv","timestamp":1620569945645,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/129.csv","timestamp":1620569946650,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/130.csv","timestamp":1620569947651,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/131.csv","timestamp":1620569948652,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/132.csv","timestamp":1620569949653,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/133.csv","timestamp":1620569950658,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/134.csv","timestamp":1620569951659,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/135.csv","timestamp":1620569952660,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/136.csv","timestamp":1620569953661,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/137.csv","timestamp":1620569954666,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/138.csv","timestamp":1620569955666,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/139.csv","timestamp":1620569956671,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/140.csv","timestamp":1620569957672,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/141.csv","timestamp":1620569958673,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/142.csv","timestamp":1620569959678,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/143.csv","timestamp":1620569960679,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/144.csv","timestamp":1620569961683,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/145.csv","timestamp":1620569962684,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/146.csv","timestamp":1620569963685,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/147.csv","timestamp":1620569964690,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/148.csv","timestamp":1620569965691,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/149.csv","timestamp":1620569966696,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/150.csv","timestamp":1620569967696,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/151.csv","timestamp":1620569968697,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/152.csv","timestamp":1620569969702,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/153.csv","timestamp":1620569970703,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/154.csv","timestamp":1620569971703,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/155.csv","timestamp":1620569972704,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/156.csv","timestamp":1620569973709,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/157.csv","timestamp":1620569974710,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/158.csv","timestamp":1620569975714,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/159.csv","timestamp":1620569976715,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/160.csv","timestamp":1620569977716,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/161.csv","timestamp":1620569978717,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/162.csv","timestamp":1620569979721,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/163.csv","timestamp":1620569980726,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/164.csv","timestamp":1620569981727,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/165.csv","timestamp":1620569982731,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/166.csv","timestamp":1620569983728,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/167.csv","timestamp":1620569984733,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/168.csv","timestamp":1620569985733,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/169.csv","timestamp":1620569986738,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/170.csv","timestamp":1620569987739,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/171.csv","timestamp":1620569988743,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/172.csv","timestamp":1620569989740,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/173.csv","timestamp":1620569990745,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/174.csv","timestamp":1620569991745,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/175.csv","timestamp":1620569992750,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/176.csv","timestamp":1620569993751,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/177.csv","timestamp":1620569994755,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/178.csv","timestamp":1620569995752,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/179.csv","timestamp":1620569996757,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/180.csv","timestamp":1620569997757,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/181.csv","timestamp":1620569998758,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/182.csv","timestamp":1620569999763,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/183.csv","timestamp":1620570000763,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/184.csv","timestamp":1620570001768,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/185.csv","timestamp":1620570002768,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/186.csv","timestamp":1620570003769,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/187.csv","timestamp":1620570004770,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/188.csv","timestamp":1620570005774,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/189.csv","timestamp":1620570006775,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/190.csv","timestamp":1620570007775,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/191.csv","timestamp":1620570008776,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/192.csv","timestamp":1620570009776,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/193.csv","timestamp":1620570010781,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/194.csv","timestamp":1620570011782,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/195.csv","timestamp":1620570012782,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/196.csv","timestamp":1620570013787,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/197.csv","timestamp":1620570014787,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/198.csv","timestamp":1620570015792,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/199.csv","timestamp":1620570016788,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/200.csv","timestamp":1620570017793,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/201.csv","timestamp":1620570018793,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/202.csv","timestamp":1620570019798,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/203.csv","timestamp":1620570020798,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/204.csv","timestamp":1620570021803,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/205.csv","timestamp":1620570022803,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/206.csv","timestamp":1620570023804,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/207.csv","timestamp":1620570024805,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/208.csv","timestamp":1620570025809,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/209.csv","timestamp":1620570026810,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/210.csv","timestamp":1620570027814,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/211.csv","timestamp":1620570028815,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/212.csv","timestamp":1620570029815,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/213.csv","timestamp":1620570030819,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/214.csv","timestamp":1620570031816,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/215.csv","timestamp":1620570032820,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/216.csv","timestamp":1620570033825,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/217.csv","timestamp":1620570034825,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/218.csv","timestamp":1620570035830,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/219.csv","timestamp":1620570036830,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/220.csv","timestamp":1620570037835,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/221.csv","timestamp":1620570038839,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/222.csv","timestamp":1620570039844,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/223.csv","timestamp":1620570040840,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/224.csv","timestamp":1620570041845,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/225.csv","timestamp":1620570042849,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/226.csv","timestamp":1620570043850,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/227.csv","timestamp":1620570044854,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/228.csv","timestamp":1620570045858,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/229.csv","timestamp":1620570046859,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/230.csv","timestamp":1620570047859,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/231.csv","timestamp":1620570048864,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/232.csv","timestamp":1620570049864,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/233.csv","timestamp":1620570050865,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/234.csv","timestamp":1620570051869,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/235.csv","timestamp":1620570052869,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/236.csv","timestamp":1620570053874,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/237.csv","timestamp":1620570054878,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/238.csv","timestamp":1620570055883,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/239.csv","timestamp":1620570056883,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/240.csv","timestamp":1620570057887,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/241.csv","timestamp":1620570058888,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/242.csv","timestamp":1620570059888,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/243.csv","timestamp":1620570060889,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/244.csv","timestamp":1620570061889,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/245.csv","timestamp":1620570062893,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/246.csv","timestamp":1620570063898,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/247.csv","timestamp":1620570064898,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/248.csv","timestamp":1620570065902,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/249.csv","timestamp":1620570066907,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/250.csv","timestamp":1620570067907,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/251.csv","timestamp":1620570068912,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/252.csv","timestamp":1620570069908,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/253.csv","timestamp":1620570070912,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/254.csv","timestamp":1620570071921,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/255.csv","timestamp":1620570072921,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/256.csv","timestamp":1620570073921,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/257.csv","timestamp":1620570074926,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/258.csv","timestamp":1620570075930,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/259.csv","timestamp":1620570076930,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/260.csv","timestamp":1620570077931,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/261.csv","timestamp":1620570078935,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/262.csv","timestamp":1620570079939,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/263.csv","timestamp":1620570080948,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/264.csv","timestamp":1620570081944,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/265.csv","timestamp":1620570082948,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/266.csv","timestamp":1620570083949,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/267.csv","timestamp":1620570084953,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/268.csv","timestamp":1620570085953,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/269.csv","timestamp":1620570086958,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/270.csv","timestamp":1620570087958,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/271.csv","timestamp":1620570088962,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/272.csv","timestamp":1620570089967,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/273.csv","timestamp":1620570090967,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/274.csv","timestamp":1620570091971,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/275.csv","timestamp":1620570092972,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/276.csv","timestamp":1620570093972,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/277.csv","timestamp":1620570094972,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/278.csv","timestamp":1620570095976,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/279.csv","timestamp":1620570096981,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/280.csv","timestamp":1620570097985,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/281.csv","timestamp":1620570098985,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/282.csv","timestamp":1620570099990,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/283.csv","timestamp":1620570100990,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/284.csv","timestamp":1620570101994,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/285.csv","timestamp":1620570102999,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/286.csv","timestamp":1620570104003,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/287.csv","timestamp":1620570105003,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/288.csv","timestamp":1620570106007,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/289.csv","timestamp":1620570107008,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/290.csv","timestamp":1620570108008,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/291.csv","timestamp":1620570109012,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/292.csv","timestamp":1620570110016,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/293.csv","timestamp":1620570111017,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/294.csv","timestamp":1620570112021,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/295.csv","timestamp":1620570113021,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/296.csv","timestamp":1620570114026,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/297.csv","timestamp":1620570115026,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/298.csv","timestamp":1620570116030,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/299.csv","timestamp":1620570117034,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/300.csv","timestamp":1620570118039,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/301.csv","timestamp":1620570119039,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/302.csv","timestamp":1620570120043,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/303.csv","timestamp":1620570121047,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/304.csv","timestamp":1620570122048,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/305.csv","timestamp":1620570123048,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/306.csv","timestamp":1620570124048,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/307.csv","timestamp":1620570125052,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/308.csv","timestamp":1620570126057,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/309.csv","timestamp":1620570127057,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/310.csv","timestamp":1620570128061,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/311.csv","timestamp":1620570129061,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/312.csv","timestamp":1620570130065,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/313.csv","timestamp":1620570131066,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/314.csv","timestamp":1620570132066,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/315.csv","timestamp":1620570133070,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/316.csv","timestamp":1620570134074,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/317.csv","timestamp":1620570135075,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/318.csv","timestamp":1620570136075,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/319.csv","timestamp":1620570137079,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/320.csv","timestamp":1620570138079,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/321.csv","timestamp":1620570139084,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/322.csv","timestamp":1620570140084,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/323.csv","timestamp":1620570141084,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/324.csv","timestamp":1620570142084,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/325.csv","timestamp":1620570143088,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/326.csv","timestamp":1620570144089,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/327.csv","timestamp":1620570145093,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/328.csv","timestamp":1620570146093,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/329.csv","timestamp":1620570147093,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/330.csv","timestamp":1620570148097,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/331.csv","timestamp":1620570149098,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/332.csv","timestamp":1620570150102,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/333.csv","timestamp":1620570151102,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/334.csv","timestamp":1620570152106,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/335.csv","timestamp":1620570153106,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/336.csv","timestamp":1620570154111,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/337.csv","timestamp":1620570155111,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/338.csv","timestamp":1620570156111,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/339.csv","timestamp":1620570157115,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/340.csv","timestamp":1620570158115,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/341.csv","timestamp":1620570159120,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/342.csv","timestamp":1620570160120,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/343.csv","timestamp":1620570161120,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/344.csv","timestamp":1620570162120,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/345.csv","timestamp":1620570163120,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/346.csv","timestamp":1620570164125,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/347.csv","timestamp":1620570165125,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/348.csv","timestamp":1620570166129,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/349.csv","timestamp":1620570167129,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/350.csv","timestamp":1620570168137,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/351.csv","timestamp":1620570169137,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/352.csv","timestamp":1620570170142,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/353.csv","timestamp":1620570171142,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/354.csv","timestamp":1620570172146,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/355.csv","timestamp":1620570173146,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/356.csv","timestamp":1620570174146,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/357.csv","timestamp":1620570175150,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/358.csv","timestamp":1620570176155,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/359.csv","timestamp":1620570177155,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/360.csv","timestamp":1620570178159,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/361.csv","timestamp":1620570179159,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/362.csv","timestamp":1620570180163,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/363.csv","timestamp":1620570181163,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/364.csv","timestamp":1620570182168,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/365.csv","timestamp":1620570183172,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/366.csv","timestamp":1620570184168,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/367.csv","timestamp":1620570185172,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/368.csv","timestamp":1620570186172,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/369.csv","timestamp":1620570187176,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/370.csv","timestamp":1620570188177,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/371.csv","timestamp":1620570189181,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/372.csv","timestamp":1620570190185,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/373.csv","timestamp":1620570191185,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/374.csv","timestamp":1620570192189,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/375.csv","timestamp":1620570193189,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/376.csv","timestamp":1620570194193,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/377.csv","timestamp":1620570195198,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/378.csv","timestamp":1620570196198,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/379.csv","timestamp":1620570197198,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/380.csv","timestamp":1620570198202,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/381.csv","timestamp":1620570199202,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/382.csv","timestamp":1620570200206,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/383.csv","timestamp":1620570201206,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/384.csv","timestamp":1620570202211,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/385.csv","timestamp":1620570203215,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/386.csv","timestamp":1620570204215,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/387.csv","timestamp":1620570205219,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/388.csv","timestamp":1620570206219,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/389.csv","timestamp":1620570207223,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/390.csv","timestamp":1620570208223,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/391.csv","timestamp":1620570209224,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/392.csv","timestamp":1620570210228,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/393.csv","timestamp":1620570211224,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/394.csv","timestamp":1620570212228,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/395.csv","timestamp":1620570213232,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/396.csv","timestamp":1620570214232,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/397.csv","timestamp":1620570215232,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/398.csv","timestamp":1620570216236,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/399.csv","timestamp":1620570217241,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/400.csv","timestamp":1620570218241,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/401.csv","timestamp":1620570219245,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/402.csv","timestamp":1620570220249,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/403.csv","timestamp":1620570221257,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/404.csv","timestamp":1620570222261,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/405.csv","timestamp":1620570223265,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/406.csv","timestamp":1620570224265,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/407.csv","timestamp":1620570225270,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/408.csv","timestamp":1620570226274,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/409.csv","timestamp":1620570227274,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/410.csv","timestamp":1620570228278,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/411.csv","timestamp":1620570229278,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/412.csv","timestamp":1620570230278,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/413.csv","timestamp":1620570231282,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/414.csv","timestamp":1620570232282,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/415.csv","timestamp":1620570233283,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/416.csv","timestamp":1620570234287,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/417.csv","timestamp":1620570235287,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/418.csv","timestamp":1620570236291,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/419.csv","timestamp":1620570237291,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/420.csv","timestamp":1620570238295,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/421.csv","timestamp":1620570239295,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/422.csv","timestamp":1620570240299,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/423.csv","timestamp":1620570241303,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/424.csv","timestamp":1620570242304,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/425.csv","timestamp":1620570243308,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/426.csv","timestamp":1620570244308,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/427.csv","timestamp":1620570245308,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/428.csv","timestamp":1620570246308,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/429.csv","timestamp":1620570247312,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/430.csv","timestamp":1620570248312,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/431.csv","timestamp":1620570249312,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/432.csv","timestamp":1620570250316,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/433.csv","timestamp":1620570251316,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/434.csv","timestamp":1620570252321,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/435.csv","timestamp":1620570253321,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/436.csv","timestamp":1620570254325,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/437.csv","timestamp":1620570255325,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/438.csv","timestamp":1620570256329,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/439.csv","timestamp":1620570257329,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/440.csv","timestamp":1620570258333,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/441.csv","timestamp":1620570259337,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/442.csv","timestamp":1620570260341,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/443.csv","timestamp":1620570261341,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/444.csv","timestamp":1620570262346,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/445.csv","timestamp":1620570263346,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/446.csv","timestamp":1620570264354,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/447.csv","timestamp":1620570265358,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/448.csv","timestamp":1620570266358,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/449.csv","timestamp":1620570267362,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/450.csv","timestamp":1620570268366,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/451.csv","timestamp":1620570269370,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/452.csv","timestamp":1620570270370,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/453.csv","timestamp":1620570271374,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/454.csv","timestamp":1620570272374,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/455.csv","timestamp":1620570273375,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/456.csv","timestamp":1620570274379,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/457.csv","timestamp":1620570275383,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/458.csv","timestamp":1620570276383,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/459.csv","timestamp":1620570277387,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/460.csv","timestamp":1620570278387,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/461.csv","timestamp":1620570279391,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/462.csv","timestamp":1620570280391,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/463.csv","timestamp":1620570281395,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/464.csv","timestamp":1620570282395,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/465.csv","timestamp":1620570283399,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/466.csv","timestamp":1620570284400,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/467.csv","timestamp":1620570285400,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/468.csv","timestamp":1620570286404,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/469.csv","timestamp":1620570287404,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/470.csv","timestamp":1620570288400,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/471.csv","timestamp":1620570289408,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/472.csv","timestamp":1620570290408,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/473.csv","timestamp":1620570291412,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/474.csv","timestamp":1620570292416,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/475.csv","timestamp":1620570293420,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/476.csv","timestamp":1620570294424,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/477.csv","timestamp":1620570295428,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/478.csv","timestamp":1620570296428,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/479.csv","timestamp":1620570297429,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/480.csv","timestamp":1620570298433,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/481.csv","timestamp":1620570299437,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/482.csv","timestamp":1620570300437,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/483.csv","timestamp":1620570301441,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/484.csv","timestamp":1620570302441,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/485.csv","timestamp":1620570303445,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/486.csv","timestamp":1620570304445,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/487.csv","timestamp":1620570305453,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/488.csv","timestamp":1620570306453,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/489.csv","timestamp":1620570307453,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/490.csv","timestamp":1620570308457,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/491.csv","timestamp":1620570309461,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/492.csv","timestamp":1620570310462,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/493.csv","timestamp":1620570311466,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/494.csv","timestamp":1620570312466,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/495.csv","timestamp":1620570313466,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/496.csv","timestamp":1620570314470,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/497.csv","timestamp":1620570315474,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/498.csv","timestamp":1620570316474,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/499.csv","timestamp":1620570317474,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/500.csv","timestamp":1620570318478,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/501.csv","timestamp":1620570319478,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/502.csv","timestamp":1620570320482,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/503.csv","timestamp":1620570321486,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/504.csv","timestamp":1620570322486,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/505.csv","timestamp":1620570323490,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/506.csv","timestamp":1620570324490,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/507.csv","timestamp":1620570325495,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/508.csv","timestamp":1620570326495,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/509.csv","timestamp":1620570327499,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/510.csv","timestamp":1620570328503,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/511.csv","timestamp":1620570329503,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/512.csv","timestamp":1620570330507,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/513.csv","timestamp":1620570331507,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/514.csv","timestamp":1620570332507,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/515.csv","timestamp":1620570333515,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/516.csv","timestamp":1620570334515,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/517.csv","timestamp":1620570335519,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/518.csv","timestamp":1620570336519,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/519.csv","timestamp":1620570337523,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/520.csv","timestamp":1620570338523,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/521.csv","timestamp":1620570339527,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/522.csv","timestamp":1620570340527,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/523.csv","timestamp":1620570341532,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/524.csv","timestamp":1620570342536,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/525.csv","timestamp":1620570343536,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/526.csv","timestamp":1620570344540,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/527.csv","timestamp":1620570345540,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/528.csv","timestamp":1620570346544,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/529.csv","timestamp":1620570347540,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/530.csv","timestamp":1620570348544,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/531.csv","timestamp":1620570349544,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/532.csv","timestamp":1620570350548,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/533.csv","timestamp":1620570351552,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/534.csv","timestamp":1620570352556,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/535.csv","timestamp":1620570353560,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/536.csv","timestamp":1620570354564,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/537.csv","timestamp":1620570355564,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/538.csv","timestamp":1620570356564,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/539.csv","timestamp":1620570357568,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/540.csv","timestamp":1620570358569,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/541.csv","timestamp":1620570359573,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/542.csv","timestamp":1620570360573,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/543.csv","timestamp":1620570361577,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/544.csv","timestamp":1620570362577,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/545.csv","timestamp":1620570363581,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/546.csv","timestamp":1620570364581,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/547.csv","timestamp":1620570365585,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/548.csv","timestamp":1620570366585,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/549.csv","timestamp":1620570367589,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/550.csv","timestamp":1620570368593,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/551.csv","timestamp":1620570369593,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/552.csv","timestamp":1620570370597,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/553.csv","timestamp":1620570371597,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/554.csv","timestamp":1620570372601,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/555.csv","timestamp":1620570373601,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/556.csv","timestamp":1620570374605,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/557.csv","timestamp":1620570375605,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/558.csv","timestamp":1620570376609,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/559.csv","timestamp":1620570377609,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/560.csv","timestamp":1620570378614,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/561.csv","timestamp":1620570379618,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/562.csv","timestamp":1620570380618,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/563.csv","timestamp":1620570381622,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/564.csv","timestamp":1620570382622,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/565.csv","timestamp":1620570383626,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/566.csv","timestamp":1620570384626,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/567.csv","timestamp":1620570385626,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/568.csv","timestamp":1620570386630,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/569.csv","timestamp":1620570387634,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/570.csv","timestamp":1620570388634,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/571.csv","timestamp":1620570389638,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/572.csv","timestamp":1620570390638,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/573.csv","timestamp":1620570391642,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/574.csv","timestamp":1620570392642,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/575.csv","timestamp":1620570393646,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/576.csv","timestamp":1620570394650,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/577.csv","timestamp":1620570395654,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/578.csv","timestamp":1620570396654,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/579.csv","timestamp":1620570397658,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/580.csv","timestamp":1620570398658,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/581.csv","timestamp":1620570399663,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/582.csv","timestamp":1620570400667,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/583.csv","timestamp":1620570401667,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/584.csv","timestamp":1620570402671,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/585.csv","timestamp":1620570403671,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/586.csv","timestamp":1620570404675,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/587.csv","timestamp":1620570405675,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/588.csv","timestamp":1620570406679,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/589.csv","timestamp":1620570407683,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/590.csv","timestamp":1620570408683,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/591.csv","timestamp":1620570409687,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/592.csv","timestamp":1620570410687,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/593.csv","timestamp":1620570411691,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/594.csv","timestamp":1620570412691,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/595.csv","timestamp":1620570413695,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/596.csv","timestamp":1620570414695,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/597.csv","timestamp":1620570415699,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/598.csv","timestamp":1620570416699,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/599.csv","timestamp":1620570417703,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/600.csv","timestamp":1620570418707,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/601.csv","timestamp":1620570419707,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/602.csv","timestamp":1620570420711,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/603.csv","timestamp":1620570421711,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/604.csv","timestamp":1620570422716,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/605.csv","timestamp":1620570423716,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/606.csv","timestamp":1620570424720,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/607.csv","timestamp":1620570425724,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/608.csv","timestamp":1620570426724,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/609.csv","timestamp":1620570427728,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/610.csv","timestamp":1620570428728,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/611.csv","timestamp":1620570429732,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/612.csv","timestamp":1620570430736,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/613.csv","timestamp":1620570431732,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/614.csv","timestamp":1620570432736,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/615.csv","timestamp":1620570433740,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/616.csv","timestamp":1620570434744,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/617.csv","timestamp":1620570435740,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/618.csv","timestamp":1620570436748,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/619.csv","timestamp":1620570437748,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/620.csv","timestamp":1620570438748,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/621.csv","timestamp":1620570439752,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/622.csv","timestamp":1620570440756,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/623.csv","timestamp":1620570441756,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/624.csv","timestamp":1620570442760,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/625.csv","timestamp":1620570443760,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/626.csv","timestamp":1620570444768,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/627.csv","timestamp":1620570445764,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/628.csv","timestamp":1620570446768,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/629.csv","timestamp":1620570447772,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/630.csv","timestamp":1620570448775,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/631.csv","timestamp":1620570449779,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/632.csv","timestamp":1620570450778,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/633.csv","timestamp":1620570451782,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/634.csv","timestamp":1620570452781,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/635.csv","timestamp":1620570453784,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/636.csv","timestamp":1620570454784,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/637.csv","timestamp":1620570455791,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/638.csv","timestamp":1620570456795,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/639.csv","timestamp":1620570457794,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/640.csv","timestamp":1620570458794,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/641.csv","timestamp":1620570459805,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/642.csv","timestamp":1620570460809,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/643.csv","timestamp":1620570461820,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/644.csv","timestamp":1620570462828,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/645.csv","timestamp":1620570463835,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/646.csv","timestamp":1620570464834,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/647.csv","timestamp":1620570465838,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/648.csv","timestamp":1620570466841,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/649.csv","timestamp":1620570467841,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/650.csv","timestamp":1620570468848,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/651.csv","timestamp":1620570469852,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/652.csv","timestamp":1620570470851,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/653.csv","timestamp":1620570471855,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/654.csv","timestamp":1620570472854,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/655.csv","timestamp":1620570473858,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/656.csv","timestamp":1620570474861,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/657.csv","timestamp":1620570475861,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/658.csv","timestamp":1620570476860,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/659.csv","timestamp":1620570477868,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/660.csv","timestamp":1620570478871,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/661.csv","timestamp":1620570479871,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/662.csv","timestamp":1620570480875,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/663.csv","timestamp":1620570481874,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/664.csv","timestamp":1620570482878,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/665.csv","timestamp":1620570483881,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/666.csv","timestamp":1620570484881,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/667.csv","timestamp":1620570485884,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/668.csv","timestamp":1620570486888,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/669.csv","timestamp":1620570487891,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/670.csv","timestamp":1620570488891,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/671.csv","timestamp":1620570489894,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/672.csv","timestamp":1620570490894,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/673.csv","timestamp":1620570491898,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/674.csv","timestamp":1620570492897,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/675.csv","timestamp":1620570493901,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/676.csv","timestamp":1620570494904,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/677.csv","timestamp":1620570495908,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/678.csv","timestamp":1620570496911,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/679.csv","timestamp":1620570497911,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/680.csv","timestamp":1620570498915,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/681.csv","timestamp":1620570499914,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/682.csv","timestamp":1620570500918,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/683.csv","timestamp":1620570501921,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/684.csv","timestamp":1620570502921,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/685.csv","timestamp":1620570503925,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/686.csv","timestamp":1620570504924,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/687.csv","timestamp":1620570505928,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/688.csv","timestamp":1620570506931,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/689.csv","timestamp":1620570507935,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/690.csv","timestamp":1620570508935,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/691.csv","timestamp":1620570509938,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/692.csv","timestamp":1620570510938,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/693.csv","timestamp":1620570511937,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/694.csv","timestamp":1620570512941,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/695.csv","timestamp":1620570513945,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/696.csv","timestamp":1620570514944,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/697.csv","timestamp":1620570515952,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/698.csv","timestamp":1620570516952,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/699.csv","timestamp":1620570517955,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/700.csv","timestamp":1620570518959,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/701.csv","timestamp":1620570519958,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/702.csv","timestamp":1620570520962,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/703.csv","timestamp":1620570521966,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/704.csv","timestamp":1620570522969,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/705.csv","timestamp":1620570523969,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/706.csv","timestamp":1620570524969,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/707.csv","timestamp":1620570525972,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/708.csv","timestamp":1620570526976,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/709.csv","timestamp":1620570527984,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/710.csv","timestamp":1620570528983,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/711.csv","timestamp":1620570529987,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/712.csv","timestamp":1620570530991,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/713.csv","timestamp":1620570531994,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/714.csv","timestamp":1620570532998,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/715.csv","timestamp":1620570533998,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/716.csv","timestamp":1620570534997,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/717.csv","timestamp":1620570536001,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/718.csv","timestamp":1620570537005,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/719.csv","timestamp":1620570538004,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/720.csv","timestamp":1620570539012,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/721.csv","timestamp":1620570540016,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/722.csv","timestamp":1620570541015,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/723.csv","timestamp":1620570542019,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/724.csv","timestamp":1620570543019,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/725.csv","timestamp":1620570544023,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/726.csv","timestamp":1620570545026,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/727.csv","timestamp":1620570546030,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/728.csv","timestamp":1620570547030,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/729.csv","timestamp":1620570548033,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/730.csv","timestamp":1620570549033,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/731.csv","timestamp":1620570550037,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/732.csv","timestamp":1620570551036,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/733.csv","timestamp":1620570552040,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/734.csv","timestamp":1620570553044,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/735.csv","timestamp":1620570554048,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/736.csv","timestamp":1620570555051,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/737.csv","timestamp":1620570556055,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/738.csv","timestamp":1620570557055,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/739.csv","timestamp":1620570558058,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/740.csv","timestamp":1620570559058,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/741.csv","timestamp":1620570560062,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/742.csv","timestamp":1620570561066,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/743.csv","timestamp":1620570562065,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/744.csv","timestamp":1620570563069,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/745.csv","timestamp":1620570564069,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/746.csv","timestamp":1620570565069,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/747.csv","timestamp":1620570566072,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/748.csv","timestamp":1620570567072,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/749.csv","timestamp":1620570568080,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/750.csv","timestamp":1620570569083,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/751.csv","timestamp":1620570570087,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/752.csv","timestamp":1620570571087,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/753.csv","timestamp":1620570572091,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/754.csv","timestamp":1620570573090,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/755.csv","timestamp":1620570574094,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/756.csv","timestamp":1620570575102,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/757.csv","timestamp":1620570576110,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/758.csv","timestamp":1620570577109,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/759.csv","timestamp":1620570578113,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/760.csv","timestamp":1620570579113,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/761.csv","timestamp":1620570580117,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/762.csv","timestamp":1620570581120,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/763.csv","timestamp":1620570582124,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/764.csv","timestamp":1620570583128,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/765.csv","timestamp":1620570584132,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/766.csv","timestamp":1620570585136,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/767.csv","timestamp":1620570586139,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/768.csv","timestamp":1620570587139,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/769.csv","timestamp":1620570588143,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/770.csv","timestamp":1620570589143,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/771.csv","timestamp":1620570590146,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/772.csv","timestamp":1620570591146,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/773.csv","timestamp":1620570592150,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/774.csv","timestamp":1620570593150,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/775.csv","timestamp":1620570594153,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/776.csv","timestamp":1620570595157,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/777.csv","timestamp":1620570596157,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/778.csv","timestamp":1620570597161,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/779.csv","timestamp":1620570598165,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/780.csv","timestamp":1620570599168,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/781.csv","timestamp":1620570600168,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/782.csv","timestamp":1620570601172,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/783.csv","timestamp":1620570602176,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/784.csv","timestamp":1620570603176,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/785.csv","timestamp":1620570604179,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/786.csv","timestamp":1620570605183,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/787.csv","timestamp":1620570606183,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/788.csv","timestamp":1620570607187,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/789.csv","timestamp":1620570608187,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/790.csv","timestamp":1620570609190,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/791.csv","timestamp":1620570610190,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/792.csv","timestamp":1620570611194,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/793.csv","timestamp":1620570612194,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/794.csv","timestamp":1620570613198,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/795.csv","timestamp":1620570614197,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/796.csv","timestamp":1620570615201,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/797.csv","timestamp":1620570616201,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/798.csv","timestamp":1620570617205,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/799.csv","timestamp":1620570618205,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/800.csv","timestamp":1620570619208,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/801.csv","timestamp":1620570620212,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/802.csv","timestamp":1620570621212,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/803.csv","timestamp":1620570622216,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/804.csv","timestamp":1620570623220,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/805.csv","timestamp":1620570624219,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/806.csv","timestamp":1620570625223,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/807.csv","timestamp":1620570626223,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/808.csv","timestamp":1620570627227,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/809.csv","timestamp":1620570628231,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/810.csv","timestamp":1620570629230,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/811.csv","timestamp":1620570630234,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/812.csv","timestamp":1620570631238,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/813.csv","timestamp":1620570632238,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/814.csv","timestamp":1620570633238,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/815.csv","timestamp":1620570634242,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/816.csv","timestamp":1620570635241,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/817.csv","timestamp":1620570636245,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/818.csv","timestamp":1620570637245,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/819.csv","timestamp":1620570638249,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/820.csv","timestamp":1620570639249,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/821.csv","timestamp":1620570640253,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/822.csv","timestamp":1620570641252,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/823.csv","timestamp":1620570642256,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/824.csv","timestamp":1620570643256,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/825.csv","timestamp":1620570644260,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/826.csv","timestamp":1620570645268,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/827.csv","timestamp":1620570646268,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/828.csv","timestamp":1620570647271,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/829.csv","timestamp":1620570648279,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/830.csv","timestamp":1620570649279,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/831.csv","timestamp":1620570650283,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/832.csv","timestamp":1620570651287,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/833.csv","timestamp":1620570652287,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/834.csv","timestamp":1620570653290,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/835.csv","timestamp":1620570654290,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/836.csv","timestamp":1620570655294,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/837.csv","timestamp":1620570656298,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/838.csv","timestamp":1620570657298,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/839.csv","timestamp":1620570658298,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/840.csv","timestamp":1620570659297,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/841.csv","timestamp":1620570660301,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/842.csv","timestamp":1620570661305,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/843.csv","timestamp":1620570662305,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/844.csv","timestamp":1620570663309,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/845.csv","timestamp":1620570664309,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/846.csv","timestamp":1620570665313,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/847.csv","timestamp":1620570666316,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/848.csv","timestamp":1620570667316,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/849.csv","timestamp":1620570668320,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/850.csv","timestamp":1620570669320,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/851.csv","timestamp":1620570670320,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/852.csv","timestamp":1620570671328,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/853.csv","timestamp":1620570672328,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/854.csv","timestamp":1620570673331,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/855.csv","timestamp":1620570674335,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/856.csv","timestamp":1620570675339,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/857.csv","timestamp":1620570676339,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/858.csv","timestamp":1620570677343,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/859.csv","timestamp":1620570678343,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/860.csv","timestamp":1620570679347,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/861.csv","timestamp":1620570680346,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/862.csv","timestamp":1620570681350,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/863.csv","timestamp":1620570682350,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/864.csv","timestamp":1620570683354,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/865.csv","timestamp":1620570684354,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/866.csv","timestamp":1620570685358,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/867.csv","timestamp":1620570686362,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/868.csv","timestamp":1620570687362,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/869.csv","timestamp":1620570688365,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/870.csv","timestamp":1620570689365,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/871.csv","timestamp":1620570690369,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/872.csv","timestamp":1620570691369,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/873.csv","timestamp":1620570692373,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/874.csv","timestamp":1620570693381,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/875.csv","timestamp":1620570694377,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/876.csv","timestamp":1620570695380,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/877.csv","timestamp":1620570696380,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/878.csv","timestamp":1620570697384,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/879.csv","timestamp":1620570698384,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/880.csv","timestamp":1620570699388,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/881.csv","timestamp":1620570700388,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/882.csv","timestamp":1620570701396,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/883.csv","timestamp":1620570702396,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/884.csv","timestamp":1620570703399,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/885.csv","timestamp":1620570704399,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/886.csv","timestamp":1620570705403,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/887.csv","timestamp":1620570706403,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/888.csv","timestamp":1620570707407,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/889.csv","timestamp":1620570708411,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/890.csv","timestamp":1620570709415,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/891.csv","timestamp":1620570710415,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/892.csv","timestamp":1620570711419,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/893.csv","timestamp":1620570712418,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/894.csv","timestamp":1620570713422,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/895.csv","timestamp":1620570714430,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/896.csv","timestamp":1620570715434,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/897.csv","timestamp":1620570716438,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/898.csv","timestamp":1620570717438,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/899.csv","timestamp":1620570718438,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/901.csv","timestamp":1620570719442,"batchId":0}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/event-time-data/900.csv","timestamp":1620570719442,"batchId":0}