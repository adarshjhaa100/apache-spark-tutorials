v1
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00000-58b421b3-832e-4547-9824-fa02ccbde14a-c000.snappy.parquet","size":590,"isDir":false,"modificationTime":1620570749006,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00001-a2396c4a-7e3e-4874-87a7-02d7933ddccb-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570749442,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00004-c8374781-9dd3-441d-858d-f74b9fffb372-c000.snappy.parquet","size":1055,"isDir":false,"modificationTime":1620570749422,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00005-9ab8d869-63b7-413d-9c37-a7e1052f4b44-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570749422,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00007-6fec474e-1d0f-4d67-9ad8-3a66dceb4bc8-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570749430,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00012-5262e7b5-dbd4-4f31-862f-c0cc8761f4f4-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570749814,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00013-03a1f01d-1fbe-4550-87d8-6985ed98cd50-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570749858,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00015-7110d912-df8d-4b6a-8fe3-ec6164041db2-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570749890,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00016-ab0ef91f-3ba8-4a24-ad2b-e60147aa3dee-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570749958,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00017-95d19759-8aec-4224-8fbb-96c445e12833-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570750018,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00019-c11d5ea0-115f-4768-8f75-c85a96cf320a-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570750074,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00025-40de0993-4d3e-4251-bb2e-81870ffa0a15-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570750346,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00027-1f53a94f-19ca-49f5-80f3-eba5cea6bd8c-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570750398,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00038-13423f8f-3b5c-4ef9-afe8-358323bafa8a-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570750978,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00041-7f032a27-09cd-4859-a7be-20a00ddd62d5-c000.snappy.parquet","size":1057,"isDir":false,"modificationTime":1620570751078,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00042-0fcb23f1-4da3-4381-8e22-73abbb617924-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751022,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00043-fbef2e47-9d00-401d-8226-0e5c182238f0-c000.snappy.parquet","size":1055,"isDir":false,"modificationTime":1620570751090,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00045-5ff2c03d-befe-4228-8464-a8e94dc33ed1-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751210,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00046-ef78962a-23b9-4561-826d-da1b01ee09ee-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751270,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00048-b514ab38-2e94-4b29-a695-e727fb95bf93-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751318,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00049-adb00de0-95ca-4aee-a3c5-4e504c5b7c1e-c000.snappy.parquet","size":1057,"isDir":false,"modificationTime":1620570751366,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00050-85eb7dc7-2a4a-48c8-8308-10626352a1b8-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751370,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00051-6845def3-84aa-4968-94cd-a96c54224c08-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751414,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00052-2f1138bd-2780-4d88-b53d-e0739bb7753e-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751486,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00053-dffd3c2a-a7eb-4b53-a7fa-31568a72d713-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751578,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00055-77fa90c6-0411-4e61-8990-5b0005831770-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751562,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00056-2d46c344-6527-4c11-88c7-1e8e2de1ef26-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751634,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00059-c2a6d989-54dc-4eac-b575-f574a490df28-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751694,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00060-348d02c2-7436-4373-9c44-94ae6c9eccfd-c000.snappy.parquet","size":1058,"isDir":false,"modificationTime":1620570751722,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00063-c939528d-e2c6-4fcd-b6d2-48d1f4ce156a-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751862,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00064-6e404ce3-27f2-4d4c-b012-2bc9a33248ee-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751966,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00065-736c3fef-ac03-4089-841f-19a82bd992cb-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570751954,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00066-2eb6ef91-db49-4a38-8ae7-138cfb2dbcaf-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570751910,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00069-f71cb53a-860a-41f4-add9-8b6acfc66c1f-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752094,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00070-2afd4266-a941-47c3-94a8-038e5c26c1d9-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752142,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00075-9557b74d-7a6b-4da6-a95a-3c1e2e9f4140-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752254,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00078-f95b6cc6-fb2c-445d-b4ec-297943975390-c000.snappy.parquet","size":1023,"isDir":false,"modificationTime":1620570752330,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00080-9fc265c6-e9be-4381-88e5-1491baadcccd-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752490,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00081-6fa9e693-8e53-407f-95e2-e7817923a1ef-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570752442,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00082-3d8ed084-fcb4-4bce-8d65-5a5cdb3ced54-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570752558,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00083-31db62bf-fb52-42f9-8cdd-86de808953cc-c000.snappy.parquet","size":1055,"isDir":false,"modificationTime":1620570752538,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00085-99c5a747-6368-476b-9968-c96dafc97161-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752666,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00087-cb0978bc-e408-44b3-bc68-6d63be56cd2e-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752698,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00088-5570508d-6481-46c5-96e6-8d3a311fc6c0-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752710,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00089-5b7cf312-c535-4ed0-858e-3d360eabf86b-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570752782,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00092-b1857123-10a8-4ffa-8ab7-9fae9d7c13db-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752826,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00093-978627bc-a2b6-4bed-93dc-c0a7640c9c2e-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752898,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00094-447093a6-b145-4cf7-8957-40441817f517-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570752874,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00096-d3c45250-a08d-4d4e-ba83-6534882cf9d8-c000.snappy.parquet","size":1069,"isDir":false,"modificationTime":1620570752942,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00097-122c6eae-2354-41d0-af6f-6865db26d0a9-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570753018,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00098-dbdad7e1-3a06-4c0a-ac33-33bc246a7d53-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753018,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00099-d1c1c43b-c6b8-4bd3-b155-20c395602526-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753046,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00100-a63d7240-0bc6-4f46-b4bb-3fe132c7b89c-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753122,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00101-da569d48-df27-4624-9840-a067dc8adc5d-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753198,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00103-c32c3b8b-06fc-4075-9435-64459140af80-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753234,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00104-e9ae49e6-68c4-4229-b030-9f7e534f5a20-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753274,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00106-09d13963-79e6-466b-9692-8e7ab331eaae-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753426,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00108-3323f322-7d47-458c-a0b9-eeb03b1a0506-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753446,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00110-cd7a4df7-40ec-442d-91a4-547527fa2fc8-c000.snappy.parquet","size":1057,"isDir":false,"modificationTime":1620570753542,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00111-33826d74-1365-43a4-a28b-72649db0176f-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570753550,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00113-afc347c1-e501-453c-a5fc-412b945dc267-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753638,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00114-989c6ecf-e959-4626-b8a8-8bc533a1ffba-c000.snappy.parquet","size":1087,"isDir":false,"modificationTime":1620570753726,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00115-10568416-d371-4c6f-a26a-7fd39c23cf25-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570753710,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00117-4bed3ce5-d54b-43ce-a62e-9a2436fd0609-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570753758,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00118-bd86cbd2-9fc1-4f5a-83d6-c0b0e454fecd-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753802,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00120-95695a80-c75d-4381-9256-60cc1cd05c64-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753846,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00121-7bb9693c-7876-4c77-a8af-c4faeff1cfa5-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753846,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00122-9b954144-128c-494c-b06b-90d20e20855e-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570753890,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00124-d2499d99-c391-46f0-a5ec-4dff9bc73ae9-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570753974,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00125-429bf128-627e-46b6-ba10-5d3d012a0d4f-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570753958,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00127-0a1fe2f3-22bd-40bf-a2f4-d0896e80eb2d-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754010,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00129-fe0e6749-ed8b-4031-bfe4-ba69146e57ad-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754126,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00131-10094f52-7ee4-4465-b91a-109485e412be-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570754178,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00132-9da423c0-faad-4821-b19f-9f1c11e28bf5-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570754174,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00133-9c3e718e-879d-45bc-a35a-f1ded33eafe1-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570754186,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00134-44b4dbde-2d1e-4543-aeac-0fac304f37bf-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754226,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00136-d9604534-b84b-49d3-88e6-f3e903ec8c40-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754306,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00139-97e64e9d-3add-4b4b-8d91-0e90a67ffaba-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754394,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00140-aac68888-bbc5-416e-bdfa-1e662d14428c-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754426,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00141-d55d6a67-7196-4947-bb86-c2e31578f7a4-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570754414,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00142-8e0a5e73-050b-4e6f-925b-afcf6841110f-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754470,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00145-7a425421-62c7-42dc-8ab6-a53036113ed7-c000.snappy.parquet","size":1023,"isDir":false,"modificationTime":1620570754570,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00146-30215559-df49-40f3-836b-49b2507102c6-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570754638,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00149-5d0518e1-6657-46bf-826c-0acaa6ca90e8-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754694,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00150-addf4495-42c2-4d31-8c1e-82de986548df-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754722,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00154-611d97de-5ce0-4d15-902a-f319b74dc801-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754886,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00157-7a1cb1c9-d9fa-45b3-aa39-dcda11a2136d-c000.snappy.parquet","size":1069,"isDir":false,"modificationTime":1620570754902,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00158-71b8100e-332a-4365-9fbb-d7baaa33f0e2-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570754970,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00159-9778a990-bf88-4dd4-99cb-60a06a720e36-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570754974,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00161-ff42f64d-a7ae-4fe0-a6c4-2da23a374c57-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755050,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00162-cf1481bd-4ee5-49ee-8077-ba01e5c4883a-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570755134,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00166-460cc5a6-4cf0-42f3-a654-b4bd6d7dd1ce-c000.snappy.parquet","size":1057,"isDir":false,"modificationTime":1620570755266,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00168-5b042a79-b9ed-4435-8b59-8c2dd44cdcb2-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755362,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00169-d84d8901-e5c8-497b-9380-544f67043a05-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570755414,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00170-6091d353-ac8c-4495-960f-d3d53c94a3da-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755430,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00171-99d5394e-ab4b-4d57-9a7a-f0fb4cc6aed9-c000.snappy.parquet","size":1023,"isDir":false,"modificationTime":1620570755518,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00172-6790ed60-f6f6-4de3-96fc-e9a9cae5715f-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755522,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00175-e2437362-1f58-4981-988b-74668d0c7d90-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755746,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00176-5e16a097-d4aa-49db-b5e5-c00ffb47c19a-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755698,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00178-f90880d8-1dd5-4fed-836e-4bda4d353af7-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570755810,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00179-39edba32-9439-4d40-9b46-b55d91b5353e-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755878,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00180-18963573-cf8d-46b4-b7c6-c4609a3fcdaa-c000.snappy.parquet","size":1058,"isDir":false,"modificationTime":1620570755838,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00181-f9b3e41d-4546-4262-93b2-fb49cd8deacf-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755878,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00183-944a2db4-eba5-407c-b414-d8c1612c4d40-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755978,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00184-f679a21f-2960-4a8f-8dc2-abdb97b30664-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570755966,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00185-8d95d7c5-7e6b-4600-b7ee-e6df7befc169-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570756010,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00187-0d47f67e-c331-4901-a1c0-07b97d14d379-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570756082,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00188-9d50e9be-1f62-4f5e-9634-b6d1896cb4cb-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570756110,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00193-69e5c9ba-6bb5-47b6-8733-7e5aae6819d8-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570756234,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00195-f1072d2a-959b-4ac4-861d-a99533605404-c000.snappy.parquet","size":1039,"isDir":false,"modificationTime":1620570756326,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00198-e5d3bae8-5f61-4211-88fb-1d242a2f7ae9-c000.snappy.parquet","size":1055,"isDir":false,"modificationTime":1620570756366,"blockReplication":1,"blockSize":33554432,"action":"add"}
{"path":"file:///home/adarsh/Documents/SparkTutorial/spark-3.1.1-bin-hadoop2.7/pycodes/data/streaming-data/file-sink/part-00199-ff8d0328-159d-4fe2-a403-d851673dd482-c000.snappy.parquet","size":1213,"isDir":false,"modificationTime":1620570756402,"blockReplication":1,"blockSize":33554432,"action":"add"}